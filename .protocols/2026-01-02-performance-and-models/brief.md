# Brief: Performance Optimization & Model Management

## Описание
Необходимо оптимизировать производительность сервера AlfaVoice и автоматизировать процесс загрузки AI моделей. Задача включает настройку компилятора Rust, оптимизацию параметров инференса (Whisper, LLM) и создание инструментов для управления файлами моделей.

## Цели
1.  **Максимальная производительность:** Обеспечить минимальную задержку (latency) при транскрипции и генерации текста.
2.  **Удобство развертывания:** Автоматизировать скачивание необходимых весов моделей.
3.  **Эффективность ресурсов:** Оптимизировать использование CPU/RAM через правильные настройки инференса.

## Требования

### 1. Управление моделями
-   Скрипт/инструмент для скачивания:
    -   Whisper `large-v3` (рекомендуется квантованная версия Q5_K_M для CPU/GPU баланса).
    -   LLM `Qwen2.5-7B-Instruct` (GGUF формат, Q5_K_M или Q4_K_M).
-   Проверка целостности файлов (SHA256).
-   Четкая структура директорий для моделей (например, `server/models/`).

### 2. Оптимизация Rust (Server)
-   Настройка профиля `release` в `Cargo.toml`:
    -   Link Time Optimization (`lto = true`).
    -   Codegen units (`codegen-units = 1` для лучшей оптимизации).
    -   Strip symbols (`strip = true`).
-   Использование инструкций процессора (AVX2/AVX-512) при компиляции.

### 3. Оптимизация Инференса
-   **Whisper:**
    -   Настройка `n_threads` (по умолчанию кол-во физических ядер / 2 или другое оптимальное значение).
    -   Подбор оптимального `beam_size` (баланс точность/скорость).
-   **LLM:**
    -   Настройка KV Cache.
    -   Настройка количества потоков.

## Критерии приемки (Definition of Done)
-   [ ] Скрипт скачивания моделей работает и загружает корректные файлы.
-   [ ] Сервер компилируется в release режиме с включенными оптимизациями.
-   [ ] Параметры инференса вынесены в конфиг или определяются динамически оптимальным образом.
-   [ ] Задержка транскрипции тестового файла (10 сек) не превышает X сек (установить baseline).