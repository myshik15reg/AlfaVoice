# Protocol: NLP Integration with Rust-BERT

**Date**: 2026-01-03
**Status**: Active
**Focus**: Интеграция библиотеки `rust-bert` и модели `ruBERT` для постобработки текста.

## 1. Цели
Интегрировать мощный NLP-движок на базе `rust-bert` (Libtorch) для улучшения качества распознавания речи и выполнения дополнительных задач обработки текста на сервере. Заменить планировавшуюся ранее интеграцию LLM Qwen через `llama.cpp`.

## 2. Требования

### Функциональные требования
1.  **Библиотека**: Использовать `rust-bert` (биндинги к Libtorch).
2.  **Модель**: Подключить `DeepPavlov/rubert-base-cased` (или аналог) для задач Masked Language Modeling (исправление ошибок) или Sequence Classification (определение интентов).
3.  **Пайплайн**:
    *   Вход: Текст от Whisper.
    *   Обработка: Исправление пунктуации, грамматики, или специфическая классификация.
    *   Выход: Очищенный текст для отправки клиенту.
4.  **Производительность**: Использовать CUDA для ускорения инференса.

### Технические требования
1.  **Зависимости**: Добавить `rust-bert` в `Cargo.toml`.
2.  **Libtorch**: Обеспечить корректную загрузку `libtorch` с поддержкой CUDA (v11.8 или v12.1 в зависимости от драйверов).
3.  **Конфигурация**: Пути к моделям должны быть конфигурируемыми (.env / config file).

## 3. Критерии приемки (Definition of Done)
- [ ] `rust-bert` успешно компилируется и линкуется с проектом.
- [ ] Модель `ruBERT` загружается при старте сервера без ошибок.
- [ ] Реализован тестовый эндпоинт или CLI-команда для проверки инференса модели.
- [ ] Инференс работает на GPU (проверка через `nvidia-smi` при нагрузке).
- [ ] Код покрыт unit-тестами.

## 4. Риски
-   **Размер Libtorch**: Библиотека весит много (>2GB с CUDA), что усложнит CI/CD и деплой.
-   **Совместимость версий**: `tch-rs` (основа `rust-bert`) очень чувствителен к версии Libtorch и CUDA.
-   **Потребление VRAM**: Одновременная работа Whisper и BERT может исчерпать 8GB VRAM на 3060 Ti.